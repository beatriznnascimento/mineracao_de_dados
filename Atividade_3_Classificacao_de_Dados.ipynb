{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypE9AaV4KRqx"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/paulotguerra/QXD0178/blob/main/02.E0-Exercicio-Classificacao-de-Dados.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvKiSskKRqx"
      },
      "source": [
        "## QXD0178 - Mineração de Dados\n",
        "# Classificação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrVTmRiYKRqy"
      },
      "source": [
        "**Professor:** Paulo de Tarso Guerra Oliveira ([paulodetarso@ufc.br](mailto:paulodetarso@ufc.br))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6yHfpamKRqz"
      },
      "source": [
        "# Lista de Exercícios: Classificação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbeO1JrPKRqz"
      },
      "source": [
        "Nesta lista de exercícios, você explorará a aplicação de métodos de aprendizado de máquina para realizar tarefas de classificação de dados. Você usará a base de dados [Food choices: College students' food and cooking preferences](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) e avaliará vários algoritmos de classificação para determinar sua eficácia. O objetivo é entender como diferentes métodos de aprendizado de máquina se comportam em relação à acurácia na classificação de dados.\n",
        "\n",
        "O exercício será dividido em várias etapas:\n",
        "\n",
        "1. **Pré-processamento dos dados:**\n",
        "   - Descreva brevemente o conjunto de dados   \n",
        "   - Limpe o conjunto de dados, tratando valores ausentes, removendo duplicatas e realizando transformações necessárias.\n",
        "   - Caso você use os dados pré-processados na lista anterior, faça um breve descritivo dos principais ajustes.\n",
        "   - Codifique variáveis categóricas, se necessário, para que possam ser utilizadas em algoritmos de aprendizado de máquina.\n",
        "   - Cria a coluna `self_perception_overweight` com valor: `True` se a coluna `self_perception_weight` tem valor 4 ou 5; e `False`, caso contrário.\n",
        "   - Remova a coluna `self_perception_weight` do conjunto de dados.\n",
        "2. **Divisão do conjunto de dados:**\n",
        "   - Divida o conjunto de dados em um conjunto de treinamento e um conjunto de teste para avaliar o desempenho dos algoritmos.\n",
        "   - O mesmo conjunto de teste deve ser usado por todos os algoritmos analizados e nenhum dado deste pode ser usado na fase de treinamento.\n",
        "   - O atributo alvo (*rótulo*) da classificação será o campo `self_perception_overweight`.   \n",
        "3. **Seleção de algoritmos de classificação:**\n",
        "   - Selecione uma variedade de algoritmos de aprendizado de máquina para testar na tarefa de classificação.   \n",
        "   - Sua seleção deve conter, no mínimo, os seguintes métodos: Naive Bayes, k-Nearest Neighbors, Support Vector Machine (Linear/RBF), Decision Trees, Random Forest, Multilayer Perceptron.\n",
        "   - Descreva brevemente como funciona cada algoritmo selecionado.\n",
        "4. **Treinamento e avaliação:**\n",
        "   - Treine os algoritmos de classificação usando todo o conjunto de treinamento.\n",
        "   - Avalie o desempenho de cada algoritmo no conjunto de teste usando métricas como acurácia, precisão, recall e F1-score.\n",
        "   - Repita a análise treinando os algoritmos com validação cruzada.\n",
        "   - Repita a análise realizando ajuste de hiperparâmetros.\n",
        "5. **Análise dos resultados:**\n",
        "   - Prepare um texto que descreva os resultados obtidos e faça uma análise crítica destes resultados.\n",
        "   - Compare o desempenho dos diferentes algoritmos e explique por que alguns apresentaram resultados mais adequados que outros.\n",
        "   \n",
        "Documente todas as etapas em um arquivo Jupyter Notebook (`.ipynb`) que inclua as análises, o código e as justificativas. Lembre-se de que é fundamental justificar todas as decisões tomadas ao longo do processo e documentar as análises de forma clara e concisa. Este trabalho tem como objetivo proporcionar uma compreensão prática da seleção e avaliação de algoritmos de classificação em cenários de aprendizado supervisionado.\n",
        "\n",
        "Envie seu Jupyter Notebook até a data de entrega especificada nesta tarefa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDU3F9lcKRq0"
      },
      "source": [
        "## Solução\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acGNWtcyx_VG"
      },
      "source": [
        "# Descrevendo o conjunto dos dados:\n",
        "\n",
        "O conjunto de dados reúne informações sobre os hábitos alimentares e o estilo de vida de estudantes universitários, oferecendo uma visão ampla sobre como eles se relacionam com a comida e a saúde. Ele inclui dados como a média acadêmica (GPA), peso e consumo diário de calorias. Também traz informações sobre o consumo de vegetais, café e vitaminas, além de práticas esportivas e preferências culinárias, como o tipo de cozinha favorita e a dieta que seguem ou desejam adotar.\n",
        "\n",
        "O conjunto também aborda aspectos emocionais, como os alimentos que os estudantes associam ao conforto e os motivos para esse consumo, como estresse ou celebrações. É ideal para explorar como diferentes fatores, como alimentação, percepções pessoais e atividades físicas, se relacionam. Ele permite entender melhor os hábitos e preferências dos estudantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5I4x4KEKRq1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "V5YbbIf6KRq1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/She-Codes-Now/Intro-to-Data-Science-with-R/master/food_coded.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb94GcnbKRq2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck59CdRQxlJ0"
      },
      "source": [
        "### Pré-processamento dos dados\n",
        "\n",
        "No código, tratei os dados passo a passo: criei a coluna self_perception_overweight a partir de self_perception_weight e removi a original. Substituí valores ausentes nas colunas numéricas pela mediana e arredondei para duas casas decimais, enquanto nas colunas categóricas, usei o valor mais frequente. Padronizei textos em colunas específicas para garantir consistência.\n",
        "\n",
        "Para lidar com o desbalanceamento entre as classes de self_perception_overweight, apliquei undersampling na classe majoritária, criando um conjunto balanceado. Em seguida, codifiquei variáveis categóricas com OneHotEncoder e escalonei os dados com StandardScaler para uniformizar a escala das variáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdeuf99KRq2",
        "outputId": "73638d23-2aec-4047-b9b0-62d7023d86f4",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formato final dos dados processados: (74, 912)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Verificar a existência da coluna 'self_perception_weight'\n",
        "if 'self_perception_weight' in df.columns:\n",
        "    df['self_perception_overweight'] = df['self_perception_weight'].apply(lambda x: True if x in [4, 5] else False)\n",
        "    df.drop(columns=['self_perception_weight'], inplace=True)\n",
        "\n",
        "# Imputação e arredondamento para colunas numéricas\n",
        "colunas_numericas = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "df[colunas_numericas] = imputer.fit_transform(df[colunas_numericas])\n",
        "df[colunas_numericas] = df[colunas_numericas].round(2)\n",
        "\n",
        "# Imputação para colunas categóricas\n",
        "colunas_nao_num = [\n",
        "    'diet_current', 'eating_changes', 'father_profession',\n",
        "    'fav_cuisine', 'food_childhood', 'healthy_meal',\n",
        "    'ideal_diet', 'meals_dinner_friend', 'mother_profession', 'type_sports'\n",
        "]\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "df[colunas_nao_num] = imputer_cat.fit_transform(df[colunas_nao_num])\n",
        "\n",
        "# Padronizar texto em colunas categóricas específicas\n",
        "def padronizar_texto(text):\n",
        "    if pd.isna(text): return text\n",
        "    return text.replace(\"and\", \",\").replace(\"/\", \",\").replace(\", \", \",\").replace(\" ,\", \",\").lower()\n",
        "\n",
        "df['comfort_food_reasons'] = df['comfort_food_reasons'].fillna('').apply(padronizar_texto)\n",
        "df['comfort_food'] = df['comfort_food'].fillna('').apply(padronizar_texto)\n",
        "\n",
        "# Balanceamento manual\n",
        "df_majority = df[df['self_perception_overweight'] == False]\n",
        "df_minority = df[df['self_perception_overweight'] == True]\n",
        "df_majority_downsampled = resample(\n",
        "    df_majority, replace=False, n_samples=len(df_minority), random_state=42\n",
        ")\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Codificação e escalonamento\n",
        "colunas_categoricas = df_balanced.select_dtypes(include=['object']).columns\n",
        "encoder = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), colunas_categoricas)\n",
        "    ],\n",
        "    remainder='passthrough'  # Mantém as colunas numéricas\n",
        ")\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "df_encoded_scaled = scaler.fit_transform(encoder.fit_transform(df_balanced))\n",
        "\n",
        "# Exibindo o formato final do DataFrame processado\n",
        "print(\"Formato final dos dados processados:\", df_encoded_scaled.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nByqOPu2KRq2"
      },
      "source": [
        "### Divisão do conjunto de dados\n",
        "\n",
        "Dividi o conjunto de dados em dois grupos: 70% para treinamento e 30% para teste, garantindo que os dados fossem bem distribuídos entre os dois conjuntos. Separei as colunas em variáveis independentes e o rótulo alvo, que é a coluna `self_perception_overweight`. Usei o método `train_test_split` do Scikit-learn para fazer a divisão, mantendo a proporção original entre as classes (True e False) com a opção `stratify`. Além disso, configurei um valor de `random_state `para garantir que os resultados possam ser reproduzidos futuramente. Com isso, o conjunto de teste será o mesmo para todos os algoritmos, sem que seus dados interfiram no treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3k2cDuE17Ox",
        "outputId": "34cbf630-07d1-41f7-e56b-3264946e8897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do conjunto de treinamento: (51, 911)\n",
            "Tamanho do conjunto de teste: (23, 911)\n",
            "Tamanho do rótulo de treinamento: (51,)\n",
            "Tamanho do rótulo de teste: (23,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# X: Todas as colunas exceto o alvo\n",
        "# y: A coluna alvo 'self_perception_overweight'\n",
        "X = df_balanced.drop(columns=['self_perception_overweight'])\n",
        "y = df_balanced['self_perception_overweight']\n",
        "\n",
        "# Aplicando a transformação e escalonamento nas variáveis categóricas\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# Dividindo o conjunto em treinamento (70%) e teste (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Verificando os tamanhos dos conjuntos\n",
        "print(\"Tamanho do conjunto de treinamento:\", X_train.shape)\n",
        "print(\"Tamanho do conjunto de teste:\", X_test.shape)\n",
        "print(\"Tamanho do rótulo de treinamento:\", y_train.shape)\n",
        "print(\"Tamanho do rótulo de teste:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUha5tciKRq2"
      },
      "source": [
        "### Seleção dos algoritmos de classificação\n",
        "\n",
        "1. **Naive Bayes**: É um modelo que calcula a probabilidade de algo pertencer a uma categoria, considerando as informações que temos. Ele é rápido e funciona bem quando as variáveis são simples e independentes, como em classificações de textos.\n",
        "\n",
        "2. **k-Nearest Neighbors (k-NN)**: Classifica um dado olhando para os dados mais próximos dele, como se comparasse características entre vizinhos. A maioria dos \"vizinhos\" decide a classificação.\n",
        "\n",
        "3. **Support Vector Machine (SVM)**: Procura uma linha ou plano que separe os dados em grupos diferentes com o maior espaço possível entre eles. Pode lidar com separações simples ou mais complexas, dependendo do tipo de configuração.\n",
        "\n",
        "4. **Decision Trees**: Funciona como um fluxograma, onde cada ponto é uma pergunta sobre os dados, levando a outras perguntas ou à resposta final. É direto e fácil de interpretar.\n",
        "\n",
        "5. **Random Forest**: É um conjunto de várias árvores de decisão que trabalham juntas. Cada árvore dá uma resposta, e o modelo escolhe a mais votada, tornando o resultado mais confiável.\n",
        "\n",
        "6. **Multilayer Perceptron (MLP)**: É uma rede de camadas que aprende padrões nos dados, como encontrar relações entre as informações. É bom para problemas mais complexos, mas pode levar mais tempo para ajustar e treinar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RS9dCxLKRq3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPTf4Qk3KRq3"
      },
      "source": [
        "### Treinamento e avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjVxhL1FJIX2"
      },
      "source": [
        "##### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8z8EiAtKRq3",
        "outputId": "2e426b93-0245-4a3d-c4a7-14500559399b",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do Naive Bayes:\n",
            "Acurácia: 0.4348\n",
            "Precisão: 0.4000\n",
            "Recall: 0.3636\n",
            "F1-Score: 0.3810\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Inicializando o modelo Naive Bayes\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_train.toarray(), y_train)  # Converta para array caso seja matriz esparsa\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_nb = naive_bayes.predict(X_test.toarray())\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "f1_nb = f1_score(y_test, y_pred_nb)\n",
        "\n",
        "print(\"\\nResultados do Naive Bayes:\")\n",
        "print(f\"Acurácia: {accuracy_nb:.4f}\")\n",
        "print(f\"Precisão: {precision_nb:.4f}\")\n",
        "print(f\"Recall: {recall_nb:.4f}\")\n",
        "print(f\"F1-Score: {f1_nb:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGkjZ-cKRq4"
      },
      "source": [
        "#####  k-Nearest Neighbors (k-NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhoEdLUeOWeK",
        "outputId": "1bb9e227-3e98-448b-d49b-650979ff7506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do k-NN:\n",
            "Acurácia: 0.4348\n",
            "Precisão: 0.4444\n",
            "Recall: 0.7273\n",
            "F1-Score: 0.5517\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Inicializando o modelo k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "f1_knn = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"\\nResultados do k-NN:\")\n",
        "print(f\"Acurácia: {accuracy_knn:.4f}\")\n",
        "print(f\"Precisão: {precision_knn:.4f}\")\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "print(f\"F1-Score: {f1_knn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmv0--lteAO3"
      },
      "source": [
        "##### Suporte Vetorial (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRGLwFFKaXi3",
        "outputId": "dfe8d868-df4b-4c1c-8a06-0a66b4cd4b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do SVM:\n",
            "Acurácia: 0.4348\n",
            "Precisão: 0.4286\n",
            "Recall: 0.5455\n",
            "F1-Score: 0.4800\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Inicializando o modelo SVM com kernel linear\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "print(\"\\nResultados do SVM:\")\n",
        "print(f\"Acurácia: {accuracy_svm:.4f}\")\n",
        "print(f\"Precisão: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F1-Score: {f1_svm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTbrvA_neL6x"
      },
      "source": [
        "#####  Árvore de Decisão (decision tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGBKzRbnadfe",
        "outputId": "69749c7c-e7ef-4080-f27a-aee3f285bd8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados da Árvore de Decisão:\n",
            "Acurácia: 0.4783\n",
            "Precisão: 0.4667\n",
            "Recall: 0.6364\n",
            "F1-Score: 0.5385\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Inicializando o modelo Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"\\nResultados da Árvore de Decisão:\")\n",
        "print(f\"Acurácia: {accuracy_dt:.4f}\")\n",
        "print(f\"Precisão: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F1-Score: {f1_dt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOvk9eWMegTZ"
      },
      "source": [
        "##### Floresta Aleatória (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy-jV8gvatcx",
        "outputId": "fdf49fef-26fc-4cf9-e6db-a7fa49ee5705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados da Floresta Aleatória:\n",
            "Acurácia: 0.6087\n",
            "Precisão: 0.6000\n",
            "Recall: 0.5455\n",
            "F1-Score: 0.5714\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Inicializando o modelo Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\nResultados da Floresta Aleatória:\")\n",
        "print(f\"Acurácia: {accuracy_rf:.4f}\")\n",
        "print(f\"Precisão: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1-Score: {f1_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKI6MGPXeqXz"
      },
      "source": [
        "##### Perceptron Multicamadas (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnFvbk3Qa4LT",
        "outputId": "671170a6-3109-472e-d2b1-8ec107128c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do Perceptron Multicamadas:\n",
            "Acurácia: 0.5217\n",
            "Precisão: 0.5000\n",
            "Recall: 0.2727\n",
            "F1-Score: 0.3529\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Inicializando o modelo MLP\n",
        "mlp = MLPClassifier(random_state=42, max_iter=500)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"\\nResultados do Perceptron Multicamadas:\")\n",
        "print(f\"Acurácia: {accuracy_mlp:.4f}\")\n",
        "print(f\"Precisão: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1-Score: {f1_mlp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPNYvy9Ifx9G"
      },
      "source": [
        "#### Validação Cruzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpqlQmPSf1oO"
      },
      "source": [
        "##### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcvN-UEGf0yc",
        "outputId": "4364cd8a-83bb-44b0-fcf6-e5939e4ddb52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - Naive Bayes:\n",
            "Acurácia: 0.5676\n",
            "Precisão: 0.5641\n",
            "Recall: 0.5946\n",
            "F1-Score: 0.5789\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Inicializando o modelo Naive Bayes\n",
        "model_nb = GaussianNB()\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_nb = cross_val_predict(model_nb, X_encoded.toarray(), y, cv=5)  # Converta para array caso seja matriz esparsa\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_nb = accuracy_score(y, y_pred_nb)\n",
        "precision_nb = precision_score(y, y_pred_nb)\n",
        "recall_nb = recall_score(y, y_pred_nb)\n",
        "f1_nb = f1_score(y, y_pred_nb)\n",
        "\n",
        "print(\"\\nValidação Cruzada - Naive Bayes:\")\n",
        "print(f\"Acurácia: {accuracy_nb:.4f}\")\n",
        "print(f\"Precisão: {precision_nb:.4f}\")\n",
        "print(f\"Recall: {recall_nb:.4f}\")\n",
        "print(f\"F1-Score: {f1_nb:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVGFa7oqf-w7"
      },
      "source": [
        "##### k-Nearest Neighbors (k-NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnzTgOzHgBsU",
        "outputId": "b4840279-da1c-48ae-bab6-51fb12d9067e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - k-NN:\n",
            "Acurácia: 0.5541\n",
            "Precisão: 0.5526\n",
            "Recall: 0.5676\n",
            "F1-Score: 0.5600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Inicializando o modelo k-NN\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_knn = cross_val_predict(model_knn, X_encoded, y, cv=5)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_knn = accuracy_score(y, y_pred_knn)\n",
        "precision_knn = precision_score(y, y_pred_knn)\n",
        "recall_knn = recall_score(y, y_pred_knn)\n",
        "f1_knn = f1_score(y, y_pred_knn)\n",
        "\n",
        "print(\"\\nValidação Cruzada - k-NN:\")\n",
        "print(f\"Acurácia: {accuracy_knn:.4f}\")\n",
        "print(f\"Precisão: {precision_knn:.4f}\")\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "print(f\"F1-Score: {f1_knn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7xa7_MPgJP_"
      },
      "source": [
        "##### Suporte Vetorial (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SK_h__zgGbA",
        "outputId": "b528d42a-956e-47fa-fc33-008e458345eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - SVM:\n",
            "Acurácia: 0.3514\n",
            "Precisão: 0.3514\n",
            "Recall: 0.3514\n",
            "F1-Score: 0.3514\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Inicializando o modelo SVM\n",
        "model_svm = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_svm = cross_val_predict(model_svm, X_encoded, y, cv=5)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_svm = accuracy_score(y, y_pred_svm)\n",
        "precision_svm = precision_score(y, y_pred_svm)\n",
        "recall_svm = recall_score(y, y_pred_svm)\n",
        "f1_svm = f1_score(y, y_pred_svm)\n",
        "\n",
        "print(\"\\nValidação Cruzada - SVM:\")\n",
        "print(f\"Acurácia: {accuracy_svm:.4f}\")\n",
        "print(f\"Precisão: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F1-Score: {f1_svm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIORa8-dgduy"
      },
      "source": [
        "##### Árvore de Decisão (decision tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA-rWN27gbpg",
        "outputId": "68240927-4f5f-49e9-d1ca-6b393252f622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - Decision Tree:\n",
            "Acurácia: 0.4865\n",
            "Precisão: 0.4878\n",
            "Recall: 0.5405\n",
            "F1-Score: 0.5128\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Inicializando o modelo Decision Tree\n",
        "model_dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_dt = cross_val_predict(model_dt, X_encoded, y, cv=5)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_dt = accuracy_score(y, y_pred_dt)\n",
        "precision_dt = precision_score(y, y_pred_dt)\n",
        "recall_dt = recall_score(y, y_pred_dt)\n",
        "f1_dt = f1_score(y, y_pred_dt)\n",
        "\n",
        "print(\"\\nValidação Cruzada - Decision Tree:\")\n",
        "print(f\"Acurácia: {accuracy_dt:.4f}\")\n",
        "print(f\"Precisão: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F1-Score: {f1_dt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BCzsO5xgn57"
      },
      "source": [
        "##### Floresta Aleatória (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AycEAGZgqh8",
        "outputId": "375df482-41a6-4434-e4e4-6181d53b33d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - Random Forest:\n",
            "Acurácia: 0.4459\n",
            "Precisão: 0.4500\n",
            "Recall: 0.4865\n",
            "F1-Score: 0.4675\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Inicializando o modelo Random Forest\n",
        "model_rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_rf = cross_val_predict(model_rf, X_encoded, y, cv=5)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_rf = accuracy_score(y, y_pred_rf)\n",
        "precision_rf = precision_score(y, y_pred_rf)\n",
        "recall_rf = recall_score(y, y_pred_rf)\n",
        "f1_rf = f1_score(y, y_pred_rf)\n",
        "\n",
        "print(\"\\nValidação Cruzada - Random Forest:\")\n",
        "print(f\"Acurácia: {accuracy_rf:.4f}\")\n",
        "print(f\"Precisão: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1-Score: {f1_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVqleIVgxMa"
      },
      "source": [
        "##### Perceptron Multicamadas (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMv7jEfkg0tZ",
        "outputId": "da03849d-5eb9-4b14-c495-1d0583005e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validação Cruzada - MLP:\n",
            "Acurácia: 0.5135\n",
            "Precisão: 0.5135\n",
            "Recall: 0.5135\n",
            "F1-Score: 0.5135\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Inicializando o modelo MLP\n",
        "model_mlp = MLPClassifier(random_state=42, max_iter=500)\n",
        "\n",
        "# Validação cruzada com 5 partições\n",
        "y_pred_mlp = cross_val_predict(model_mlp, X_encoded, y, cv=5)\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_mlp = accuracy_score(y, y_pred_mlp)\n",
        "precision_mlp = precision_score(y, y_pred_mlp)\n",
        "recall_mlp = recall_score(y, y_pred_mlp)\n",
        "f1_mlp = f1_score(y, y_pred_mlp)\n",
        "\n",
        "print(\"\\nValidação Cruzada - MLP:\")\n",
        "print(f\"Acurácia: {accuracy_mlp:.4f}\")\n",
        "print(f\"Precisão: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1-Score: {f1_mlp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GCbU3-wkYTH"
      },
      "source": [
        "#### Ajustando hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w8xpgTKkfZ4"
      },
      "source": [
        "##### Naive Bayes\n",
        "\n",
        "Não possui hiperparâmetros significativos para ajuste no contexto atual, então este modelo será mantido como está."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtyCkYmqqrQQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Inicializando o modelo Naive Bayes\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_train.toarray(), y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_nb = naive_bayes.predict(X_test.toarray())\n",
        "\n",
        "# Calculando métricas\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "f1_nb = f1_score(y_test, y_pred_nb)\n",
        "\n",
        "print(\"\\nResultados do Naive Bayes:\")\n",
        "print(f\"Acurácia: {accuracy_nb:.4f}\")\n",
        "print(f\"Precisão: {precision_nb:.4f}\")\n",
        "print(f\"Recall: {recall_nb:.4f}\")\n",
        "print(f\"F1-Score: {f1_nb:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjUWNZqhnlmE"
      },
      "source": [
        "##### k-Nearest Neighbors (k-NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7s5Dk22nuEj",
        "outputId": "1ea4529f-8020-418d-a226-e106d2084ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do k-NN:\n",
            "Accuracy: 0.4348\n",
            "Precision: 0.4375\n",
            "Recall: 0.6364\n",
            "F1 Score: 0.5185\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Ajuste de hiperparâmetros e treinamento\n",
        "model_knn = KNeighborsClassifier(n_neighbors=15)\n",
        "model_knn.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred_knn = model_knn.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "f1_knn = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"\\nResultados do k-NN:\")\n",
        "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
        "print(f\"Precision: {precision_knn:.4f}\")\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "print(f\"F1 Score: {f1_knn:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0m3JqSVpVsI"
      },
      "source": [
        "##### Suporte Vetorial (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJac4kEdpY0D",
        "outputId": "b56a8a27-1b78-4a6c-cafd-5ba75c1376b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do SVM:\n",
            "Accuracy: 0.4348\n",
            "Precision: 0.4286\n",
            "Recall: 0.5455\n",
            "F1 Score: 0.4800\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Ajuste de hiperparâmetros e treinamento\n",
        "model_svm = SVC(kernel='linear', C=1)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "print(\"\\nResultados do SVM:\")\n",
        "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
        "print(f\"Precision: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F1 Score: {f1_svm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMnDVKh2pfbN"
      },
      "source": [
        "##### Árvore de Decisão (decision tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqBl3OcypdAP",
        "outputId": "78e9d7fd-3e6e-4dff-aa96-a15d33521561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados da Árvore de Decisão:\n",
            "Accuracy: 0.4783\n",
            "Precision: 0.4667\n",
            "Recall: 0.6364\n",
            "F1 Score: 0.5385\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Ajuste de hiperparâmetros e treinamento\n",
        "model_dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "model_dt.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred_dt = model_dt.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"\\nResultados da Árvore de Decisão:\")\n",
        "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Precision: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F1 Score: {f1_dt:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVyCQ4Fqpo8w"
      },
      "source": [
        "##### Floresta Aleatória (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmd9815pplEL",
        "outputId": "1fdbb245-75e8-43a6-db13-7c15506debda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados da Floresta Aleatória:\n",
            "Accuracy: 0.6087\n",
            "Precision: 0.6000\n",
            "Recall: 0.5455\n",
            "F1 Score: 0.5714\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Ajuste de hiperparâmetros e treinamento\n",
        "model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\nResultados da Floresta Aleatória:\")\n",
        "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1 Score: {f1_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8__FfJupwHE"
      },
      "source": [
        "##### Perceptron Multicamadas (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a60FXgGppyM6",
        "outputId": "866becd1-c7cd-4625-abfa-328b111fa868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do Perceptron Multicamadas:\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.5000\n",
            "Recall: 0.2727\n",
            "F1 Score: 0.3529\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Ajuste de hiperparâmetros e treinamento\n",
        "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "model_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred_mlp = model_mlp.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"\\nResultados do Perceptron Multicamadas:\")\n",
        "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
        "print(f\"Precision: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1 Score: {f1_mlp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj1DY1vQKRq4"
      },
      "source": [
        "### Análise dos resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iVXOuIPxKm2"
      },
      "source": [
        "##### **Resultados do Naive Bayes:**\n",
        "\n",
        "**Teste:**\n",
        "\n",
        "Acurácia: 0.4348\n",
        "\n",
        "Precisão: 0.4000\n",
        "\n",
        "Recall: 0.3636\n",
        "\n",
        "F1-Score: 0.3810\n",
        "\n",
        "\n",
        "**Validação Cruzada:**\n",
        "\n",
        "Acurácia: 0.5676\n",
        "\n",
        "Precisão: 0.5641\n",
        "\n",
        "Recall: 0.5946\n",
        "\n",
        "F1-Score: 0.5789\n",
        "\n",
        "**O Naive Bayes apresentou baixa acurácia e recall no teste, mostrando dificuldade em capturar os padrões nos dados. Contudo, a validação cruzada indicou que ele generaliza melhor em diferentes subconjuntos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad80FR10kxxG"
      },
      "source": [
        "###### Resultados do KNN\n",
        "\n",
        "**Resultados do k-NN:**\n",
        "\n",
        "Acurácia: 0.4348\n",
        "\n",
        "Precisão: 0.4444\n",
        "\n",
        "Recall: 0.7273\n",
        "\n",
        "F1-Score: 0.5517\n",
        "\n",
        "**Validação Cruzada - k-NN:**\n",
        "\n",
        "Acurácia: 0.5541\n",
        "\n",
        "Precisão: 0.5526\n",
        "\n",
        "Recall: 0.5676\n",
        "\n",
        "F1-Score: 0.5600\n",
        "\n",
        "**Ajustando hiperparâmetros do k-NN:**\n",
        "\n",
        "Accuracy: 0.4348\n",
        "\n",
        "Precision: 0.4375\n",
        "\n",
        "Recall: 0.6364\n",
        "\n",
        "F1 Score: 0.5185\n",
        "\n",
        "\n",
        "**O k-NN se destacou pelo recall alto no teste, sendo eficiente em identificar positivos. Porém, ajustes de hiperparâmetros não trouxeram melhorias. Seu desempenho é sensível a ruídos e variações nos dados.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjZ7quDQyu5g"
      },
      "source": [
        "##### Resultados do Suporte Vetorial (SVM)\n",
        "\n",
        "Acurácia: 0.4348\n",
        "\n",
        "Precisão: 0.4286\n",
        "\n",
        "Recall: 0.5455\n",
        "\n",
        "F1-Score: 0.4800\n",
        "\n",
        "**Validação Cruzada - SVM:**\n",
        "\n",
        "Acurácia: 0.3514\n",
        "\n",
        "Precisão: 0.3514\n",
        "\n",
        "Recall: 0.3514\n",
        "\n",
        "F1-Score: 0.3514\n",
        "\n",
        "**Ajustando hiperparametros do SVM:**\n",
        "\n",
        "Accuracy: 0.4348\n",
        "\n",
        "Precision: 0.4286\n",
        "\n",
        "Recall: 0.5455\n",
        "\n",
        "F1 Score: 0.4800\n",
        "\n",
        " **SVM apresentou desempenho limitado, com baixa acurácia e um F1-Score de 0.4800 no teste. Isso sugere que ele teve dificuldades para encontrar uma separação clara entre as classes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euRYcaF40B1t"
      },
      "source": [
        "##### Resultados da Árvore de Decisão:\n",
        "\n",
        "Acurácia: 0.4783\n",
        "\n",
        "Precisão: 0.4667\n",
        "\n",
        "Recall: 0.6364\n",
        "\n",
        "F1-Score: 0.5385\n",
        "\n",
        "**Validação Cruzada - Decision Tree:**\n",
        "\n",
        "Acurácia: 0.4865\n",
        "\n",
        "Precisão: 0.4878\n",
        "\n",
        "Recall: 0.5405\n",
        "\n",
        "F1-Score: 0.5128\n",
        "\n",
        "**Ajustando hiperparâmetros da Árvore de Decisão:**\n",
        "\n",
        "Accuracy: 0.4783\n",
        "\n",
        "Precision: 0.4667\n",
        "\n",
        "Recall: 0.6364\n",
        "\n",
        "F1 Score: 0.5385\n",
        "\n",
        "**A Árvore de Decisão foi eficiente no recall e teve uma boa precisão em geral. Seu desempenho consistente nos diferentes cenários mostra que ela foi robusta com os dados.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0WP5BQu0UE4"
      },
      "source": [
        "###### Resultados da Floresta Aleatória:\n",
        "\n",
        "Acurácia: 0.6087\n",
        "\n",
        "Precisão: 0.6000\n",
        "\n",
        "Recall: 0.5455\n",
        "\n",
        "F1-Score: 0.5714\n",
        "\n",
        "**Validação Cruzada - Random Forest:**\n",
        "\n",
        "Acurácia: 0.4459\n",
        "\n",
        "Precisão: 0.4500\n",
        "\n",
        "Recall: 0.4865\n",
        "\n",
        "F1-Score: 0.4675\n",
        "\n",
        "**Ajustando hiperparâmetros da Floresta Aleatória:**\n",
        "\n",
        "Accuracy: 0.6087\n",
        "\n",
        "Precision: 0.6000\n",
        "\n",
        "Recall: 0.5455\n",
        "\n",
        "F1 Score: 0.5714\n",
        "\n",
        "**A Floresta Aleatória se destacou como o melhor algoritmo geral, apresentando o F1-Score mais alto no teste (0.5714) e uma acurácia de 0.6087, a maior entre todos os modelos. Sua precisão foi elevada (0.6000), indicando que a maioria das previsões positivas estava correta, e o recall moderado (0.5455) mostrou que conseguiu capturar mais da metade dos casos positivos reais. Essa combinação reflete um bom equilíbrio entre evitar falsos positivos e identificar positivos reais.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU1aV8RE0rkm"
      },
      "source": [
        "##### Resultados do Perceptron Multicamadas:\n",
        "\n",
        "Acurácia: 0.5217\n",
        "\n",
        "Precisão: 0.5000\n",
        "\n",
        "Recall: 0.2727\n",
        "\n",
        "F1-Score: 0.3529\n",
        "\n",
        "**Validação Cruzada - MLP:**\n",
        "\n",
        "Acurácia: 0.5135\n",
        "\n",
        "Precisão: 0.5135\n",
        "\n",
        "Recall: 0.5135\n",
        "\n",
        "F1-Score: 0.5135\n",
        "\n",
        "**Ajustando hiperparâmetros do Perceptron Multicamadas:**\n",
        "\n",
        "Accuracy: 0.5217\n",
        "\n",
        "Precision: 0.5000\n",
        "\n",
        "Recall: 0.2727\n",
        "\n",
        "F1 Score: 0.3529\n",
        "\n",
        "**O MLP teve baixo desempenho no teste, com F1-Score de 0.3529, principalmente devido ao recall limitado (0.2727). Isso indica dificuldade em identificar corretamente os positivos.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK7f8gRh1u_T"
      },
      "source": [
        "### Comparação Geral dos Algoritmos:\n",
        "\n",
        "A análise dos algoritmos de classificação mostrou diferenças claras no desempenho, com a Floresta Aleatória se destacando como a opção mais confiável. Esse modelo conseguiu o melhor equilíbrio entre as métricas, com boa acurácia (60,87%), precisão (60%) e recall (54,55%). A combinação de múltiplas árvores permitiu capturar padrões mais complexos e lidar bem com os dados. No entanto, na validação cruzada, o desempenho caiu, sugerindo que o modelo pode estar levemente ajustado demais ao conjunto de treino, o que é comum em métodos baseados em árvores.\n",
        "\n",
        "Outros modelos, como o k-NN e a Árvore de Decisão, também tiveram resultados interessantes, especialmente em recall, demonstrando eficiência em identificar casos positivos. O k-NN, por exemplo, foi capaz de capturar mais de 72% dos positivos no teste, mas sua precisão menor indica que ele teve dificuldades em evitar falsos positivos. A Árvore de Decisão mostrou-se um pouco mais equilibrada, mas ainda inferior à Floresta Aleatória.\n",
        "\n",
        "Por outro lado, o Naive Bayes teve desempenho mediano, mas sua generalização na validação cruzada foi boa, o que reflete sua simplicidade e eficácia em problemas mais diretos. Já modelos mais complexos, como o SVM e o Perceptron Multicamadas (MLP), apresentaram dificuldades. O SVM parece não ter conseguido capturar os padrões necessários, provavelmente devido à escolha do kernel linear, enquanto o MLP foi limitado pela quantidade de dados e ajustes insuficientes, o que prejudicou seu recall.\n",
        "\n",
        "De forma geral, a Floresta Aleatória foi a escolha mais eficaz para os dados analisados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
